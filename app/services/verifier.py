from __future__ import annotations

import hashlib
import json
import logging
from typing import Tuple

from sqlalchemy.orm import Session

from ..schemas import CheckRequest, CheckResponse, ClaimAnalysis
from ..models import CachedResult
from .nlp import extract_entities, extract_ngrams
from .news_client import NewsClient
from .llm_client import LLMClient

# Configure logger
logger = logging.getLogger(__name__)


def _hash_claim(text: str, style: str) -> str:
    h = hashlib.sha256()
    h.update(text.strip().encode("utf-8"))
    h.update(style.encode("utf-8"))
    return h.hexdigest()


def _format_formal_explanation(
    claim: str,
    status: str,
    probability: float | None,
    entities: dict,
    news_count: int,
    base_explanation: str,
) -> str:
    prob_text = f"{probability:.2f}" if probability is not None else "Ð½Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð°"
    ent_parts = []
    for k, vals in entities.items():
        if vals:
            ent_parts.append(f"{k}: {', '.join(vals)}")
    entities_text = "; ".join(ent_parts) if ent_parts else "ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚Ð¸ Ð½Ðµ Ð²Ñ‹Ð´ÐµÐ»ÐµÐ½Ñ‹"

    status_human = {
        "confirmed": "Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¾ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ñ‹Ð¼Ð¸ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ°Ð¼Ð¸",
        "not_found": "Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ð¹ Ð² Ð½Ð¾Ð²Ð¾ÑÑ‚ÑÑ… Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ (Ð½Ð¸Ð·ÐºÐ°Ñ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ)",
        "uncertain": "Ð¿Ñ€ÑÐ¼Ñ‹Ñ… Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ð¹ Ð½ÐµÑ‚ (ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ ÑƒÐ¼ÐµÑ€ÐµÐ½Ð½Ð¾ Ð¿Ñ€Ð°Ð²Ð´Ð¾Ð¿Ð¾Ð´Ð¾Ð±Ð½Ð¾)",
    }.get(status, status)

    return (
        f"ÐŸÑ€Ð¾Ð²ÐµÐ´ÐµÐ½Ð° Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ:\n\n"
        f"Â«{claim}Â».\n\n"
        f"ÐÐ° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ñ‹Ñ… Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¹ Ð¸ Ð¸Ð·Ð²Ð»ÐµÑ‡Ñ‘Ð½Ð½Ñ‹Ñ… ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÐµÐ¹ "
        f"ÑÐ¸ÑÑ‚ÐµÐ¼Ð° ÑÑ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð»Ð° ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ Ð²Ñ‹Ð²Ð¾Ð´: {status_human}. "
        f"ÐžÑ†ÐµÐ½Ð¾Ñ‡Ð½Ð°Ñ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ Ð¸ÑÑ‚Ð¸Ð½Ð½Ð¾ÑÑ‚Ð¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ: {prob_text}.\n\n"
        f"Ð’Ñ‹Ð´ÐµÐ»ÐµÐ½Ð½Ñ‹Ðµ ÑÑƒÑ‰Ð½Ð¾ÑÑ‚Ð¸: {entities_text}. "
        f"ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ñ‹Ñ… Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸Ð¹ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÑŽÑŽ Ð½ÐµÐ´ÐµÐ»ÑŽ: {news_count}. "
        f"Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· (AI):\n\n{base_explanation}\n\n"
        f"Ð’Ñ‹Ð²Ð¾Ð´ Ð½Ð¾ÑÐ¸Ñ‚ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð½Ñ‹Ð¹ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€ Ð¸ Ð½Ðµ ÑÐ²Ð»ÑÐµÑ‚ÑÑ ÑŽÑ€Ð¸Ð´Ð¸Ñ‡ÐµÑÐºÐ¸ Ð·Ð½Ð°Ñ‡Ð¸Ð¼Ñ‹Ð¼."
    )


def _format_simple_explanation(status: str, probability: float | None) -> str:
    if probability is None:
        return "ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð¾Ñ†ÐµÐ½ÐºÐ¸."

    if status == "confirmed":
        base = "ÐÐ°ÑˆÐ»Ð¸ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ Ð² Ð½Ð¾Ð²Ð¾ÑÑ‚ÑÑ…."
    elif status == "not_found":
        base = "Ð’ Ð½Ð¾Ð²Ð¾ÑÑ‚ÑÑ… Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¸ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ð¹. Ð¡Ð¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð¼Ð°Ð»Ð¾Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾."
    else:
        base = "ÐŸÑ€ÑÐ¼Ñ‹Ñ… Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ð¹ Ð½ÐµÑ‚."

    if probability >= 0.8:
        prob_text = "Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾, ÑÑ‚Ð¾ Ð¿Ñ€Ð°Ð²Ð´Ð°."
    elif probability >= 0.5:
        prob_text = "ÐŸÐ¾Ñ…Ð¾Ð¶Ðµ Ð½Ð° Ð¿Ñ€Ð°Ð²Ð´Ñƒ, Ð½Ð¾ Ð½Ðµ Ñ‚Ð¾Ñ‡Ð½Ð¾."
    elif probability >= 0.3:
        prob_text = "Ð¡Ð¾Ð¼Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾."
    else:
        prob_text = "ÐœÐ°Ð»Ð¾Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾."

    return f"{base} {prob_text}".strip()


async def verify_claim(
    db: Session,
    payload: CheckRequest,
    news_client: NewsClient | None = None,
    llm_client: LLMClient | None = None,
) -> CheckResponse:
    news_client = news_client or NewsClient()
    llm_client = llm_client or LLMClient()

    logger.info("ðŸ” ÐÐÐ§ÐÐ›Ðž ÐŸÐ ÐžÐ’Ð•Ð ÐšÐ˜ Ð£Ð¢Ð’Ð•Ð Ð–Ð”Ð•ÐÐ˜Ð¯")
    
    claim = payload.text.strip()
    style = payload.style

    print(f"\n=== ðŸš€ Verifying claim: {claim} ===")

    claim_hash = _hash_claim(claim, style)
    cached = db.query(CachedResult).filter_by(claim_hash=claim_hash).first()
    if cached:
        print("âš¡ Loaded from CACHE")
        data = json.loads(cached.result_json)
        return CheckResponse(**data, cached=True)

    print("ðŸ” Cache not found, running fresh analysis...")

    entities = extract_entities(claim)
    ngrams = extract_ngrams(claim, n=2)
    print(f"ðŸ”Ž Entities extracted: {entities}")
    print(f"ðŸ”— N-grams: {ngrams}")

    news_results = await news_client.search(claim, from_days=7, limit=5)

    print("\n=== ðŸ“¡ NEWS RESULTS DEBUG ===")
    if news_results:
        print(f"ðŸ“° Found {len(news_results)} result(s):")
        for nr in news_results:
            print(f"   â€¢ {nr}")
    else:
        print("ðŸ—ž No news results found.")

    if news_results:
        status = "confirmed"
        probability = 0.9
        explanation_base = (
            f"ÐŸÐ¾ Ð½Ð°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ð¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð½Ñ‹Ð¼ Ð¿ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ†Ð¸ÑÐ¼ ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ Ð¿Ð¾Ð´Ñ‚Ð²ÐµÑ€Ð¶Ð´Ð°ÐµÑ‚ÑÑ. "
            f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹: {len(news_results)}."
        )
    else:
        context_summary = "No matching news articles found for this claim within the last 7 days."
        try:
            probability, llm_explanation = await llm_client.analyze(
                f"Claim: {claim}\nContext: {context_summary}"
            )

            print("\n=== ðŸ¤– LLM ANALYSIS DEBUG ===")
            print(f"ðŸ’¬ Claim: {claim}")
            print(f"ðŸ“Š Probability: {probability}")
            print(f"ðŸ“ Explanation:\n{llm_explanation}")

        except Exception as e:
            probability = 0.3
            llm_explanation = f"AI-Ð°Ð½Ð°Ð»Ð¸Ð· Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {e}"
            print(f"\n=== âŒ LLM ERROR ===\n{e}")

        status = "uncertain" if probability >= 0.4 else "not_found"
        explanation_base = llm_explanation

    print(f"\nðŸ“Œ Final status: {status} (prob={probability:.2f})")

    explanation = (
        _format_formal_explanation(claim, status, probability, entities, len(news_results), explanation_base)
        if style == "formal"
        else _format_simple_explanation(status, probability)
    )

    analysis = ClaimAnalysis(
        status=status,
        probability=probability,
        explanation=explanation,
        matched_sources=news_results,
    )

    resp_obj = CheckResponse(
        claim=claim,
        style=style,
        analysis=analysis,
        cached=False,
    )

    print("\nðŸ’¾ Saving result to cache...")
    db.add(CachedResult(claim_hash=claim_hash, result_json=resp_obj.json()))
    db.commit()

    print("âœ… Done.\n")
    return resp_obj
